::gemini::models ns

api-request ::gemini::api/request
HttpError ::gemini::api/HttpError
is-ok-response ::hot::http/is-ok-response

FunctionCallingConfig type {
    mode: "MODE_UNSPECIFIED" | "AUTO" | "ANY" | "NONE"?,
    allowedFunctionNames: Vec<Str>?
}

GoogleSearchRetrieval type {
    dynamicRetrievalConfig: DynamicRetrievalConfig?
}

GroundingSupport type {
    segment: Segment?,
    groundingChunkIndices: Vec<Int>?,
    confidenceScores: Vec<Float>?
}

RetrievalMetadata type {
    googleSearchDynamicRetrievalScore: Float?
}

LogprobsCandidate type {
    token: Str?,
    tokenId: Int?,
    logProbability: Float?
}

EmbedContentResponse type {
    embedding: ContentEmbedding?
}

ErrorResponse type {
    error: Status?
}

FunctionResponse type {
    name: Str?,
    response: Map?
}

ListModelsResponse type {
    models: Vec<Model>?,
    nextPageToken: Str?
}

Schema type {
    type: "TYPE_UNSPECIFIED" | "STRING" | "NUMBER" | "INTEGER" | "BOOLEAN" | "ARRAY" | "OBJECT"?,
    format: Str?,
    description: Str?,
    nullable: Bool?,
    enum: Vec<Str>?,
    items: Schema?,
    properties: Map?,
    required: Vec<Str>?
}

GroundingChunk type {
    web: Web?,
    retrievedContext: RetrievedContext?
}

CountTokensResponse type {
    totalTokens: Int?,
    cachedContentTokenCount: Int?
}

ToolConfig type {
    functionCallingConfig: FunctionCallingConfig?
}

SafetySetting type {
    category: "HARM_CATEGORY_UNSPECIFIED" | "HARM_CATEGORY_DEROGATORY" | "HARM_CATEGORY_TOXICITY" | "HARM_CATEGORY_VIOLENCE" | "HARM_CATEGORY_SEXUAL" | "HARM_CATEGORY_MEDICAL" | "HARM_CATEGORY_DANGEROUS" | "HARM_CATEGORY_HARASSMENT" | "HARM_CATEGORY_HATE_SPEECH" | "HARM_CATEGORY_SEXUALLY_EXPLICIT" | "HARM_CATEGORY_DANGEROUS_CONTENT" | "HARM_CATEGORY_CIVIC_INTEGRITY"?,
    threshold: "HARM_BLOCK_THRESHOLD_UNSPECIFIED" | "BLOCK_LOW_AND_ABOVE" | "BLOCK_MEDIUM_AND_ABOVE" | "BLOCK_ONLY_HIGH" | "BLOCK_NONE" | "OFF"?
}

ContentEmbedding type {
    values: Vec<Float>?
}

Blob type {
    mimeType: Str?,
    data: Str?
}

GenerateContentResponse type {
    candidates: Vec<Candidate>?,
    promptFeedback: PromptFeedback?,
    usageMetadata: UsageMetadata?,
    modelVersion: Str?
}

CitationSource type {
    startIndex: Int?,
    endIndex: Int?,
    uri: Str?,
    license: Str?
}

GenerateContentRequest type {
    contents: Vec<Content>,
    systemInstruction: Content?,
    tools: Vec<Tool>?,
    toolConfig: ToolConfig?,
    safetySettings: Vec<SafetySetting>?,
    generationConfig: GenerationConfig?,
    cachedContent: Str?
}

GenerationConfig type {
    stopSequences: Vec<Str>?,
    responseMimeType: Str?,
    responseSchema: Schema?,
    candidateCount: Int?,
    maxOutputTokens: Int?,
    temperature: Float?,
    topP: Float?,
    topK: Int?,
    presencePenalty: Float?,
    frequencyPenalty: Float?,
    responseLogprobs: Bool?,
    logprobs: Int?
}

Web type {
    uri: Str?,
    title: Str?
}

Segment type {
    partIndex: Int?,
    startIndex: Int?,
    endIndex: Int?,
    text: Str?
}

FunctionCall type {
    name: Str?,
    args: Map?
}

PromptFeedback type {
    blockReason: "BLOCK_REASON_UNSPECIFIED" | "SAFETY" | "OTHER" | "BLOCKLIST" | "PROHIBITED_CONTENT"?,
    safetyRatings: Vec<SafetyRating>?
}

BatchEmbedContentsRequest type {
    requests: Vec<EmbedContentRequest>
}

Model type {
    name: Str?,
    baseModelId: Str?,
    version: Str?,
    displayName: Str?,
    description: Str?,
    inputTokenLimit: Int?,
    outputTokenLimit: Int?,
    supportedGenerationMethods: Vec<Str>?,
    temperature: Float?,
    maxTemperature: Float?,
    topP: Float?,
    topK: Int?
}

FileData type {
    mimeType: Str?,
    fileUri: Str?
}

SafetyRating type {
    category: Str?,
    probability: "HARM_PROBABILITY_UNSPECIFIED" | "NEGLIGIBLE" | "LOW" | "MEDIUM" | "HIGH"?,
    blocked: Bool?
}

CodeExecutionResult type {
    outcome: "OUTCOME_UNSPECIFIED" | "OUTCOME_OK" | "OUTCOME_FAILED" | "OUTCOME_DEADLINE_EXCEEDED"?,
    output: Str?
}

UsageMetadata type {
    promptTokenCount: Int?,
    cachedContentTokenCount: Int?,
    candidatesTokenCount: Int?,
    totalTokenCount: Int?
}

Part type {
    text: Str?,
    inlineData: Blob?,
    fileData: FileData?,
    functionCall: FunctionCall?,
    functionResponse: FunctionResponse?,
    executableCode: ExecutableCode?,
    codeExecutionResult: CodeExecutionResult?
}

Tool type {
    functionDeclarations: Vec<FunctionDeclaration>?,
    codeExecution: Map?,
    googleSearch: Map?,
    googleSearchRetrieval: GoogleSearchRetrieval?
}

Status type {
    code: Int?,
    message: Str?,
    details: Vec<Map>?
}

EmbedContentRequest type {
    content: Content,
    taskType: "TASK_TYPE_UNSPECIFIED" | "RETRIEVAL_QUERY" | "RETRIEVAL_DOCUMENT" | "SEMANTIC_SIMILARITY" | "CLASSIFICATION" | "CLUSTERING" | "QUESTION_ANSWERING" | "FACT_VERIFICATION"?,
    title: Str?,
    outputDimensionality: Int?
}

ExecutableCode type {
    language: "LANGUAGE_UNSPECIFIED" | "PYTHON"?,
    code: Str?
}

FunctionDeclaration type {
    name: Str?,
    description: Str?,
    parameters: Schema?
}

DynamicRetrievalConfig type {
    mode: "MODE_UNSPECIFIED" | "MODE_DYNAMIC"?,
    dynamicThreshold: Float?
}

CountTokensRequest type {
    contents: Vec<Content>?,
    generateContentRequest: GenerateContentRequest?
}

GroundingMetadata type {
    webSearchQueries: Vec<Str>?,
    searchEntryPoint: SearchEntryPoint?,
    groundingChunks: Vec<GroundingChunk>?,
    groundingSupports: Vec<GroundingSupport>?,
    retrievalMetadata: RetrievalMetadata?
}

LogprobsResult type {
    topCandidates: Vec<TopCandidates>?,
    chosenCandidates: Vec<LogprobsCandidate>?
}

Candidate type {
    content: Content?,
    finishReason: "FINISH_REASON_UNSPECIFIED" | "STOP" | "MAX_TOKENS" | "SAFETY" | "RECITATION" | "LANGUAGE" | "OTHER" | "BLOCKLIST" | "PROHIBITED_CONTENT" | "SPII" | "MALFORMED_FUNCTION_CALL"?,
    safetyRatings: Vec<SafetyRating>?,
    citationMetadata: CitationMetadata?,
    tokenCount: Int?,
    groundingMetadata: GroundingMetadata?,
    avgLogprobs: Float?,
    logprobsResult: LogprobsResult?,
    index: Int?
}

CitationMetadata type {
    citationSources: Vec<CitationSource>?
}

SearchEntryPoint type {
    renderedContent: Str?,
    sdkBlob: Str?
}

Content type {
    parts: Vec<Part>?,
    role: "user" | "model"?
}

RetrievedContext type {
    uri: Str?,
    title: Str?
}

TopCandidates type {
    candidates: Vec<LogprobsCandidate>?
}

BatchEmbedContentsResponse type {
    embeddings: Vec<ContentEmbedding>?
}

ModelsListRequest type {
  page-size: Str,
  page-token: Str
}

ModelsListResponse type {
    models: Vec<Model>?,
    nextPageToken: Str?
}


list
meta {doc: "GET /v1/models - List Models"}
fn (request: ModelsListRequest): ModelsListResponse {
  response api-request("GET", `${::gemini/BASE_URL}/v1/models?pageSize=${request.page-size}&pageToken=${request.page-token}`)
  if(is-ok-response(response), ModelsListResponse(response.body), err(HttpError(response)))
}

ModelsGetRequest type {
  model: Str
}

ModelsGetResponse type {
    name: Str?,
    baseModelId: Str?,
    version: Str?,
    displayName: Str?,
    description: Str?,
    inputTokenLimit: Int?,
    outputTokenLimit: Int?,
    supportedGenerationMethods: Vec<Str>?,
    temperature: Float?,
    maxTemperature: Float?,
    topP: Float?,
    topK: Int?
}


get
meta {doc: "GET /v1/models/{model} - Get Model"}
fn (request: ModelsGetRequest): ModelsGetResponse {
  response api-request("GET", `${::gemini/BASE_URL}/v1/models/${request.model}`)
  if(is-ok-response(response), ModelsGetResponse(response.body), err(HttpError(response)))
}

ModelsGenerateContentRequest type {
    contents: Vec<Content>,
    systemInstruction: Content?,
    tools: Vec<Tool>?,
    toolConfig: ToolConfig?,
    safetySettings: Vec<SafetySetting>?,
    generationConfig: GenerationConfig?,
    cachedContent: Str?
}

ModelsGenerateContentResponse type {
    candidates: Vec<Candidate>?,
    promptFeedback: PromptFeedback?,
    usageMetadata: UsageMetadata?,
    modelVersion: Str?
}


generate-content
meta {doc: "POST /v1/models/{model}:generateContent - Generate Content"}
fn (model: Str, request: ModelsGenerateContentRequest): ModelsGenerateContentResponse {
  response api-request("POST", `${::gemini/BASE_URL}/v1/models/${model}:generateContent`, {}, request)
  if(is-ok-response(response), ModelsGenerateContentResponse(response.body), err(HttpError(response)))
}

ModelsStreamGenerateContentRequest type {
    contents: Vec<Content>,
    systemInstruction: Content?,
    tools: Vec<Tool>?,
    toolConfig: ToolConfig?,
    safetySettings: Vec<SafetySetting>?,
    generationConfig: GenerationConfig?,
    cachedContent: Str?
}

ModelsStreamGenerateContentResponse type {
    candidates: Vec<Candidate>?,
    promptFeedback: PromptFeedback?,
    usageMetadata: UsageMetadata?,
    modelVersion: Str?
}


stream-generate-content
meta {doc: "POST /v1/models/{model}:streamGenerateContent - Stream Generate Content"}
fn (model: Str, alt: Str, request: ModelsStreamGenerateContentRequest): ModelsStreamGenerateContentResponse {
  response api-request("POST", `${::gemini/BASE_URL}/v1/models/${model}:streamGenerateContent?alt=${alt}`, {}, request)
  if(is-ok-response(response), ModelsStreamGenerateContentResponse(response.body), err(HttpError(response)))
}

ModelsCountTokensRequest type {
    contents: Vec<Content>?,
    generateContentRequest: GenerateContentRequest?
}

ModelsCountTokensResponse type {
    totalTokens: Int?,
    cachedContentTokenCount: Int?
}


count-tokens
meta {doc: "POST /v1/models/{model}:countTokens - Count Tokens"}
fn (model: Str, request: ModelsCountTokensRequest): ModelsCountTokensResponse {
  response api-request("POST", `${::gemini/BASE_URL}/v1/models/${model}:countTokens`, {}, request)
  if(is-ok-response(response), ModelsCountTokensResponse(response.body), err(HttpError(response)))
}

ModelsEmbedContentRequest type {
    content: Content,
    taskType: "TASK_TYPE_UNSPECIFIED" | "RETRIEVAL_QUERY" | "RETRIEVAL_DOCUMENT" | "SEMANTIC_SIMILARITY" | "CLASSIFICATION" | "CLUSTERING" | "QUESTION_ANSWERING" | "FACT_VERIFICATION"?,
    title: Str?,
    outputDimensionality: Int?
}

ModelsEmbedContentResponse type {
    embedding: ContentEmbedding?
}


embed-content
meta {doc: "POST /v1/models/{model}:embedContent - Embed Content"}
fn (model: Str, request: ModelsEmbedContentRequest): ModelsEmbedContentResponse {
  response api-request("POST", `${::gemini/BASE_URL}/v1/models/${model}:embedContent`, {}, request)
  if(is-ok-response(response), ModelsEmbedContentResponse(response.body), err(HttpError(response)))
}

ModelsBatchEmbedContentsRequest type {
    requests: Vec<EmbedContentRequest>
}

ModelsBatchEmbedContentsResponse type {
    embeddings: Vec<ContentEmbedding>?
}


batch-embed-contents
meta {doc: "POST /v1/models/{model}:batchEmbedContents - Batch Embed Contents"}
fn (model: Str, request: ModelsBatchEmbedContentsRequest): ModelsBatchEmbedContentsResponse {
  response api-request("POST", `${::gemini/BASE_URL}/v1/models/${model}:batchEmbedContents`, {}, request)
  if(is-ok-response(response), ModelsBatchEmbedContentsResponse(response.body), err(HttpError(response)))
}
