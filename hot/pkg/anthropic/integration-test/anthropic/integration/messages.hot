::anthropic::integration::messages ns
meta ["test"]

// =============================================================================
// Integration Tests for Anthropic Messages API
// =============================================================================
// These tests require ANTHROPIC_API_KEY to be set in context (via ctx.hot or conf)

// -----------------------------------------------------------------------------
// Basic Message Tests
// -----------------------------------------------------------------------------

test-messages-post-simple
meta ["test"]
fn () {
    request ::anthropic::messages/MessagesPostRequest({
        model: "claude-3-haiku-20240307",
        max_tokens: 100,
        messages: [{role: "user", content: "Say 'Hello, Hot!' and nothing else."}]
    })

    response ::anthropic::messages/post(request)

    assert(response.id, "Response should have an id")
    assert(response.role, "Response should have a role")
    assert(response.content, "Response should have content")
    assert(gt(length(response.content), 0), "Response content should not be empty")
    assert(response.usage, "Response should have usage info")
}

test-messages-post-with-system
meta ["test"]
fn () {
    request ::anthropic::messages/MessagesPostRequest({
        model: "claude-3-haiku-20240307",
        max_tokens: 100,
        system: "You are a helpful assistant that always responds in JSON format.",
        messages: [{role: "user", content: "What is 2+2? Respond with {\"answer\": <number>}"}]
    })

    response ::anthropic::messages/post(request)

    assert(response.id, "Response should have an id")
    assert(response.content, "Response should have content")
    assert(gt(length(response.content), 0), "Response content should not be empty")
}

// -----------------------------------------------------------------------------
// Streaming Tests
// -----------------------------------------------------------------------------

test-messages-post-stream
meta ["test"]
fn () {
    request ::anthropic::messages/MessagesPostRequest({
        model: "claude-3-haiku-20240307",
        max_tokens: 50,
        messages: [{role: "user", content: "Count from 1 to 3."}]
    })

    response ::anthropic::messages/post-stream(request)

    // Verify we get a streaming response
    assert-eq(200, response.status, "Streaming response should have status 200")
    assert(response.body, "Streaming response should have body iterator")

    // Collect events from the stream and verify we got some
    events collect(response.body)
    assert(gt(length(events), 0), "Should receive at least one streaming event")
}

test-messages-stream-collect-text
meta ["test"]
fn () {
    request ::anthropic::messages/MessagesPostRequest({
        model: "claude-3-haiku-20240307",
        max_tokens: 100,
        messages: [{role: "user", content: "Write a haiku about programming."}]
    })

    response ::anthropic::messages/post-stream(request)
    assert-eq(200, response.status, "Should get 200 status")

    // Collect events - SSE events have {event: "type", data: {...}} structure
    events collect(response.body)
    assert(gt(length(events), 0), "Should have events")
    
    // Check that stream completed (has message_stop event)
    stop-events filter(events, (e) { eq(e.event, "message_stop") })
    assert(gt(length(stop-events), 0), "Stream should complete with message_stop event")
    
    // Check we have some content events (content_block_start or content_block_delta)
    content-events filter(events, (e) { 
        or(eq(e.event, "content_block_start"), eq(e.event, "content_block_delta"))
    })
    assert(gt(length(content-events), 0), "Should have content events")
}

// -----------------------------------------------------------------------------
// Multi-turn Conversation Tests
// -----------------------------------------------------------------------------

test-messages-multi-turn
meta ["test"]
fn () {
    request ::anthropic::messages/MessagesPostRequest({
        model: "claude-3-haiku-20240307",
        max_tokens: 100,
        messages: [
            {role: "user", content: "My name is Alice."},
            {role: "assistant", content: "Nice to meet you, Alice!"},
            {role: "user", content: "What is my name?"}
        ]
    })

    response ::anthropic::messages/post(request)

    assert(response.id, "Response should have an id")
    assert(response.content, "Response should have content")
    
    // The response should mention "Alice" since that was in the conversation
    first-block first(response.content)
    assert(first-block, "Should have at least one content block")
}

// -----------------------------------------------------------------------------
// Parameter Tests
// -----------------------------------------------------------------------------

test-messages-with-temperature
meta ["test"]
fn () {
    // Low temperature should give more deterministic output
    request ::anthropic::messages/MessagesPostRequest({
        model: "claude-3-haiku-20240307",
        max_tokens: 50,
        temperature: 0.0,
        messages: [{role: "user", content: "What is 1+1? Reply with just the number."}]
    })

    response ::anthropic::messages/post(request)

    assert(response.id, "Response should have an id")
    assert(response.content, "Response should have content")
}

test-messages-with-stop-sequence
meta ["test"]
fn () {
    request ::anthropic::messages/MessagesPostRequest({
        model: "claude-3-haiku-20240307",
        max_tokens: 200,
        stop_sequences: ["STOP"],
        messages: [{role: "user", content: "Count from 1 to 10, then write STOP, then count from 11 to 20."}]
    })

    response ::anthropic::messages/post(request)

    assert(response.id, "Response should have an id")
    // If stop sequence worked, stop_reason should be "stop_sequence"
    // Note: The model might not always trigger the stop sequence
    assert(response.content, "Response should have content")
}

test-messages-max-tokens-limit
meta ["test"]
fn () {
    // Request with very low max_tokens to verify it's respected
    request ::anthropic::messages/MessagesPostRequest({
        model: "claude-3-haiku-20240307",
        max_tokens: 5,
        messages: [{role: "user", content: "Write a very long essay about the history of computing."}]
    })

    response ::anthropic::messages/post(request)

    assert(response.id, "Response should have an id")
    assert(response.usage, "Response should have usage info")
    // Output tokens should be limited
    assert(lte(response.usage.output_tokens, 10), "Output tokens should be limited by max_tokens")
}

// -----------------------------------------------------------------------------
// Tool Use Tests
// -----------------------------------------------------------------------------

test-messages-with-tools
meta ["test"]
fn () {
    request ::anthropic::messages/MessagesPostRequest({
        model: "claude-3-haiku-20240307",
        max_tokens: 200,
        tools: [
            {
                name: "get_weather",
                description: "Get the current weather for a location",
                input_schema: {
                    type: "object",
                    properties: {
                        location: {
                            type: "string",
                            description: "The city and state, e.g. San Francisco, CA"
                        }
                    },
                    required: ["location"]
                }
            }
        ],
        messages: [{role: "user", content: "What's the weather in San Francisco?"}]
    })

    response ::anthropic::messages/post(request)

    assert(response.id, "Response should have an id")
    assert(response.content, "Response should have content")
    // When tools are provided and relevant, the model may use them
    // stop_reason could be "tool_use" or "end_turn"
    assert(response.stop_reason, "Response should have a stop reason")
}
