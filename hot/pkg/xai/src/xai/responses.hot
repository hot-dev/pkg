::xai::responses ns

// ============================================================================
// xAI Chat Responses API
// https://docs.x.ai/docs/guides/chat
// ============================================================================

api-request ::xai::api/request
api-request-stream ::xai::api/request-stream
HttpError ::xai::api/HttpError
is-ok-response ::hot::http/is-ok-response

// ============================================================================
// Types
// ============================================================================

// Literal union for message roles
Role type "user" | "system" | "assistant" | "tool"

// Literal union for finish reasons
FinishReason type "stop" | "length" | "tool_calls" | "content_filter"

// Literal union for response status
ResponseStatus type "completed" | "failed" | "incomplete" | "in_progress"

// Message input for requests
InputMessage type {
    role: Role,
    content: Any,
    name: Str?,
    tool_calls: Vec<ToolCall>?,
    tool_call_id: Str?
}

// Tool call structure
ToolCall type {
    id: Str,
    type: Str,
    function: FunctionCall
}

FunctionCall type {
    name: Str,
    arguments: Str
}

// Tool definition
Tool type {
    type: Str,
    function: FunctionDefinition
}

FunctionDefinition type {
    name: Str,
    description: Str?,
    parameters: Any?,
    strict: Bool?
}

// Response format configuration
ResponseFormat type {
    type: Str,
    json_schema: Any?
}

// Create response request
CreateResponseRequest type {
    model: Str,
    input: Any,
    instructions: Str?,
    max_output_tokens: Int?,
    temperature: Float?,
    top_p: Float?,
    tools: Vec<Tool>?,
    tool_choice: Any?,
    parallel_tool_calls: Bool?,
    response_format: ResponseFormat?,
    store: Bool?,
    metadata: Map?,
    stream: Bool?,
    reasoning: ReasoningConfig?,
    previous_response_id: Str?
}

// Reasoning configuration (for extended thinking)
ReasoningConfig type {
    effort: Str?,
    encrypted_content: Str?
}

// Output item types
OutputItem type {
    type: Str,
    id: Str?,
    status: Str?,
    role: Role?,
    content: Vec<ContentPart>?,
    name: Str?,
    arguments: Str?,
    call_id: Str?,
    output: Str?
}

ContentPart type {
    type: Str,
    text: Str?,
    annotations: Vec<Any>?
}

// Token usage
Usage type {
    input_tokens: Int,
    output_tokens: Int,
    total_tokens: Int?,
    input_tokens_details: TokenDetails?,
    output_tokens_details: TokenDetails?
}

TokenDetails type {
    cached_tokens: Int?,
    reasoning_tokens: Int?
}

// Create response result
CreateResponseResponse type {
    id: Str,
    object: Str,
    created_at: Int,
    model: Str,
    status: ResponseStatus,
    output: Vec<OutputItem>,
    usage: Usage?,
    error: Any?,
    incomplete_details: Any?,
    metadata: Map?
}

// Streaming response wrapper
StreamingResponseResponse type {
    status: Int,
    headers: Map,
    body: Any  // Iterator yielding stream events
}

// Stream event types
StreamEvent type {
    type: Str,
    response: CreateResponseResponse?,
    output_index: Int?,
    item: OutputItem?,
    content_index: Int?,
    part: ContentPart?,
    delta: Str?
}

// ============================================================================
// Non-Streaming API
// ============================================================================

create
meta {
    doc: "Create a response (non-streaming).

The Responses API is the recommended way to interact with xAI models.
It supports stateful conversations where previous prompts and responses
are stored server-side for 30 days.

**Example**
```hot
response create({
    model: \"grok-3\",
    input: \"What is the capital of France?\",
    max_output_tokens: 1024
})
```

**With conversation history**
```hot
response create({
    model: \"grok-3\",
    input: [
        {role: \"user\", content: \"Hello!\"},
        {role: \"assistant\", content: \"Hi there!\"},
        {role: \"user\", content: \"What can you do?\"}
    ]
})
```

**Continue a previous conversation**
```hot
response create({
    model: \"grok-3\",
    input: \"Tell me more\",
    previous_response_id: \"resp_abc123\"
})
```"
}
fn (request: CreateResponseRequest): CreateResponseResponse {
    response api-request("POST", `${::xai/BASE_URL}/responses`, {}, request)
    if(is-ok-response(response), CreateResponseResponse(response.body), err(HttpError(response)))
}

// ============================================================================
// Streaming API
// ============================================================================

create-stream
meta {
    doc: "Create a streaming response. Returns an iterator that yields SSE events.

**Event Types**
- `response.created` - Initial response metadata
- `response.output_item.added` - New output item started
- `response.content_part.added` - Content part started
- `response.output_text.delta` - Text chunk
- `response.output_text.done` - Text output complete
- `response.output_item.done` - Output item complete
- `response.completed` - Full response complete

**Example**
```hot
response create-stream({
    model: \"grok-3\",
    input: \"Write a short poem about coding\"
})

for-each(response.body, fn (event) {
    cond {
        eq(event.type, \"response.output_text.delta\") => {
            print(event.delta)
        }

        eq(event.type, \"response.completed\") => {
            println(\"Done!\")
        }
    }
})
```"
}
fn (request: CreateResponseRequest): StreamingResponseResponse {
    // Force stream: true
    streaming-request merge(untype(request), {stream: true})
    response api-request-stream("POST", `${::xai/BASE_URL}/responses`, {}, streaming-request, "sse")
    cond {
        gte(response.status, 400) => { err(HttpError(response)) }
        => { StreamingResponseResponse(response) }
    }
}

// ============================================================================
// Retrieve Response
// ============================================================================

get
meta {
    doc: "Retrieve a previously created response by ID.

**Example**
```hot
response get(\"resp_abc123\")
```"
}
fn (response-id: Str): CreateResponseResponse {
    response api-request("GET", `${::xai/BASE_URL}/responses/${response-id}`)
    if(is-ok-response(response), CreateResponseResponse(response.body), err(HttpError(response)))
}

// ============================================================================
// Delete Response
// ============================================================================

delete
meta {
    doc: "Delete a stored response. This removes it from server-side storage.

**Example**
```hot
delete(\"resp_abc123\")
```"
}
fn (response-id: Str): Map {
    response api-request("DELETE", `${::xai/BASE_URL}/responses/${response-id}`)
    if(is-ok-response(response), ok(response.body), err(HttpError(response)))
}

// ============================================================================
// Convenience Functions
// ============================================================================

chat
meta {
    doc: "Simple chat - send a message and get a response string.

**Example**
```hot
response chat(\"grok-3\", \"What is the capital of France?\")
// Returns: \"The capital of France is Paris.\"
```"
}
fn
(model: Str, message: Str): Str {
    chat(model, message, null, null)
},
(model: Str, message: Str, system: Str): Str {
    chat(model, message, system, null)
},
(model: Str, message: Str, system: Str, max-tokens: Int): Str {
    request {
        model: model,
        input: message,
        instructions: system,
        max_output_tokens: or(max-tokens, 4096)
    }

    response create(CreateResponseRequest(request))

    match response {
        Result.Err => { err(response) }
        Result.Ok => { extract-response-text(response) }
    }
}

// Helper to build a user message
user-message
meta { doc: "Create a user message" }
fn (content: Str): InputMessage {
    InputMessage({role: "user", content: content})
}

// Helper to build a system message
system-message
meta { doc: "Create a system message" }
fn (content: Str): InputMessage {
    InputMessage({role: "system", content: content})
}

// Helper to build an assistant message
assistant-message
meta { doc: "Create an assistant message" }
fn (content: Str): InputMessage {
    InputMessage({role: "assistant", content: content})
}

// Extract text from a response
extract-response-text
meta {
    doc: "Extract the text content from a response. Returns empty string if no content."
}
fn (response: CreateResponseResponse): Str {
    output response.output
    cond {
        or(is-null(output), is-zero(length(output))) => { "" }
        => {
            // Find the first message output item
            message-item find(output, (item) { eq(item.type, "message") })
            cond {
                is-null(message-item) => { "" }
                => {
                    content message-item.content
                    cond {
                        or(is-null(content), is-zero(length(content))) => { "" }
                        => {
                            // Find first text content part
                            text-part find(content, (part) { eq(part.type, "output_text") })
                            cond {
                                is-null(text-part) => { "" }
                                => { or(text-part.text, "") }
                            }
                        }
                    }
                }
            }
        }
    }
}

// Extract text delta from a streaming event
extract-delta-text
meta {
    doc: "Extract the text content from a streaming SSE event. Returns empty string if no content."
}
fn (event): Str {
    cond {
        is-null(event) => { "" }
        is-null(event.data) => { "" }
        => {
            data event.data
            cond {
                not(eq(data.type, "response.output_text.delta")) => { "" }
                => { or(data.delta, "") }
            }
        }
    }
}

// Check if a streaming event indicates completion
is-stream-done
meta { doc: "Check if a streaming event indicates the stream is complete" }
fn (event): Bool {
    cond {
        is-null(event) => { false }
        is-null(event.data) => { false }
        => {
            data event.data
            or(
                eq(data.type, "response.completed"),
                eq(data.type, "response.failed"),
                eq(data.type, "response.incomplete")
            )
        }
    }
}
